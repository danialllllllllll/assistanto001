import time
import random
import threading
import os
import shutil
import zipfile
from datetime import datetime
from flask import Flask, jsonify, request, send_file, render_template, session, redirect
from flask_cors import CORS
import numpy as np
import networkx as nx
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from io import BytesIO
from queue import Queue, Empty
import json
from typing import List, Tuple
import psutil                               # resource monitoring
import requests
from bs4 import BeautifulSoup               # web scraping
import ast
import importlib.util
from scipy.spatial import KDTree            # fast graph queries
# -------------------------------------------------

# === FLASK APP (ONE TIME ONLY) ===
app = Flask(__name__, template_folder=os.path.join(os.path.dirname(__file__), 'interfaces', 'templates'))
CORS(app)
app.secret_key = 'super_secret_key_123'

# === SAFE DEAP IMPORT ===
try:
    from deap import base, creator, tools
    if not hasattr(creator, "FitnessMax"):
        creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    if not hasattr(creator, "Individual"):
        creator.create("Individual", list, fitness=creator.FitnessMax)
except ImportError as e:
    print("FATAL: 'deap' not installed. Run: pip install deap")
    raise e

# === CONFIGURATION (YOUR ORIGINAL) ===
STAGES = [
    {"name": "Baby Steps Phase", "target": "patterns", "learning_rate": 0.1, "age_equiv": "0-18 months", "min_iterations": 50},
    {"name": "Toddler Phase", "target": "memory", "learning_rate": 0.1, "age_equiv": "18 months-3 years", "min_iterations": 50},
    {"name": "Pre-K Phase", "target": "coherence", "learning_rate": 0.1, "age_equiv": "3-5 years", "min_iterations": 50},
    {"name": "Elementary Phase", "target": "questioning", "learning_rate": 0.1, "age_equiv": "5-14 years", "min_iterations": 100},
    {"name": "Teen Phase", "target": "personality", "learning_rate": 0.1, "age_equiv": "14-18 years", "min_iterations": 100},
    {"name": "Scholar Phase", "target": "truth_detection", "learning_rate": 0.1, "age_equiv": "18-22 years", "min_iterations": 150},
    {"name": "Thinker Phase", "target": "philosophy", "learning_rate": 0.1, "age_equiv": "22+ years", "min_iterations": 200}
]

CORE_VALUES = [
    {"name": "Kindness", "priority": 1.0, "status": "Enforced"},
    {"name": "Understanding", "priority": 1.0, "status": "Enforced"},
    {"name": "Truth", "priority": 1.0, "status": "Enforced"},
    {"name": "Positive Relationships", "priority": 1.0, "status": "Enforced"},
    {"name": "Non-Harm", "priority": 1.0, "status": "Enforced"}
]

UNDERSTANDING_REQUIREMENTS = {"minimum_understanding": 0.999, "minimum_confidence": 0.95}
WEB_PASSWORD = "OVER//RIDE"
KILL_SWITCH_PHRASE = "confirm delete"

# Dataset
DATA_SIZE = 1000
FEATURES = 20
CLASSES = 4
data_inputs = np.random.rand(DATA_SIZE, FEATURES)
data_outputs = np.random.randint(0, CLASSES, DATA_SIZE)

# === FULL CURRICULUM (YOUR ORIGINAL) ===
STAGE_TOPICS = {
    "Baby Steps Phase": ["Animal sounds", "Bright colors", "Simple shapes", "minimal speech"],
    "Toddler Phase": [
        "Naming animals", "Basic actions (e.g., dog runs)", "Pet care basics",
        "identifying shapes", "simple counting", "simple speech", "Toddler essentials"
    ],
    "Pre-K Phase": [
        "Animal stories", "Animal emotions", "Simple habitats",
        "Preschool Math", "Preschool English", "Preschool Foreign Language",
        "Preschool History", "Preschool Geography", "Preschool Science",
        "Preschool Art", "Preschool Music", "Preschool Physical Education", "Preschool Health"
    ],
    "Elementary Phase": [
        "Animal life cycles", "Basic classification (mammals/birds)", "Animal habitats",
        "Earth Science", "Right vs Wrong", "Basic Math", "Basic English", "Foreign Language",
        "History", "Geography", "Science", "Art", "Music", "Physical Education", "Health",
        "Social Studies", "Elementary Thinking", "Elementary Problem Solving",
        "Elementary Decision Making", "Elementary Critical Thinking", "Elementary Problem Solving", "Elementary Topics"
    ],
    "Teen Phase": [
        "Animal ecology", "Conservation ethics", "Human-animal interactions",
        "Human History", "War", "World Events", "Complex College Level topics",
        "Advanced Math", "Advanced English", "Advanced Foreign Language", "Advanced Science",
        "Advanced Art", "Advanced Music", "Advanced Physical Education", "Advanced Health",
        "Advanced Social Studies", "Complex Thinking", "Critical Thinking", "Problem Solving",
        "Decision Making", "Ethical Dilemmas", "Philosophical Questions", "Logical Reasoning",
        "Psychological Insights", "Sociological Perspectives", "Economic Principles",
        "Political Systems", "Environmental Issues", "Highschool Level Topics", "Theory",
        "Astronomy", "Astrology", "Cosmology", "Physics", "Chemistry", "Biology", "Geology",
        "Mathematics", "Computer Science", "Engineering", "Medicine", "Law", "Politics",
        "Economics", "Sociology", "All advanced level Science fields", "Mathematics",
        "Computer Science", "Engineering", "Medicine", "Law", "Politics", "Economics",
        "Every Subject supplied to a high school student"
    ],
    "Scholar Phase": [
        "Animal evolution", "Genetic adaptations", "Wildlife misinformation detection",
        "Ethical dilemmas in conservation", "Advanced Philosophy", "Advanced Ethics",
        "Advanced Logic", "Advanced Psychology", "Advanced Sociology", "Advanced Metaphysics",
        "Advanced Epistemology", "Advanced Ontology", "Advanced Aesthetics", "Advanced Ethics",
        "Advanced Logic", "Advanced Epistemology", "Advanced Ontology", "Advanced Aesthetics",
        "Advanced Mathematics", "Advanced Computer Science", "Advanced Engineering",
        "Advanced Medicine", "Advanced Law", "Advanced Politics", "Advanced Economics",
        "Advanced Sociology", " #%$ Advanced Environmental Science", "Advanced Physics",
        "Advanced Chemistry", "Advanced Biology", "All advanced level Science fields",
        "Advanced Mathematics", "Advanced Computer Science", "Advanced Engineering",
        "Advanced Medicine", "Advanced Law", "Advanced Politics", "Advanced Economics",
        "Advanced Sociology", "Advanced Environmental Science", "Advanced Physics",
        "All Advanced level Mathematic fields", "Advanced Computer Science", "Advanced Engineering",
        "Advanced Medicine", "Advanced Law", "Advanced Politics", "Advanced Economics",
        "Advanced Sociology", "Advanced Environmental Science", "Advanced Physics",
        "Advanced Chemistry", "Advanced Biology", "All advanced Geography fields",
        "Advanced History", "Advanced World Events", "Advanced War", "Advanced Human History",
        "Advanced World Events", "Advanced War", "Advanced Human History", "Advanced World Events",
        "Advanced War", "Advanced Human History", "All Advanced Language Arts fields",
        "Advanced English", "Advanced Foreign Language", "Advanced Literature", "Advanced Writing",
        "Advanced Reading", "Advanced Speaking", "Advanced Listening", "Advanced Grammar",
        "Advanced Vocabulary", "Advanced Syntax", "Advanced Semantics"
    ],
    "Thinker Phase": [
        "Animal consciousness", "Philosophical animal rights", "Ethical dilemmas in ecology",
        "Everything in the universe", "The meaning of life", "The nature of reality",
        "The nature of consciousness", "The nature of time", "The nature of space",
        "The nature of matter", "The nature of energy", "The nature of information",
        "The nature of knowledge", "The nature of truth", "The nature of beauty",
        "The nature of goodness", "The nature of evil", "The nature of love",
        "The nature of hate", "Everything the world has to offer", "Absolutely everything",
        "Complex Theories"
    ]
}

# -------------------------------------------------
# NEW: Knowledge node for graph-based memory
# -------------------------------------------------
class KnowledgeNode:
    """A single fact / concept with connections and reinforcement strength."""
    def __init__(self, data: str, connections=None):
        self.data = data
        self.connections = connections or []
        self.strength = 1.0

    def reinforce(self, reward: float):
        self.strength = max(0.1, self.strength + reward)

# -------------------------------------------------
# HIERARCHICAL ARCHIVER (STABLE) – unchanged
# -------------------------------------------------
class HierarchicalArchiver:
    def __init__(self, base_dir='training_archives'):
        self.base_dir = base_dir
        self.current_phase = ""
        self.generation_buffer = []
        self.batch_count = 0
        os.makedirs(base_dir, exist_ok=True)

    def set_phase(self, phase_name: str) -> str:
        self.current_phase = phase_name.lower().replace(' ', '_')
        phase_path = os.path.join(self.base_dir, self.current_phase)
        os.makedirs(phase_path, exist_ok=True)
        self.batch_count = 0
        return phase_path

    def save_generation(self, generation_data: dict) -> None:
        self.generation_buffer.append(generation_data)
        if len(self.generation_buffer) >= 10:
            self._create_batch_zip()

    def _create_batch_zip(self) -> None:
        if not self.current_phase or not self.generation_buffer:
            return
        phase_path = os.path.join(self.base_dir, self.current_phase)
        temp_dir = os.path.join(phase_path, f'temp_batch_{self.batch_count}')
        os.makedirs(temp_dir, exist_ok=True)
        for gen_data in self.generation_buffer:
            filename = os.path.join(temp_dir, f'generation_{gen_data["iteration"]}.json')
            with open(filename, 'w') as f:
                json.dump(gen_data, f, indent=2)
        zip_path = os.path.join(phase_path, f'batch_{self.batch_count:04d}.zip')
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, _, files in os.walk(temp_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, temp_dir)
                    zipf.write(file_path, arcname)
        shutil.rmtree(temp_dir, ignore_errors=True)
        self.generation_buffer = []
        self.batch_count += 1
        print(f"  Archived batch {self.batch_count-1} -> {zip_path}")

# -------------------------------------------------
# TRAINING OPTIMIZER (STABLE) – unchanged
# -------------------------------------------------
class TrainingOptimizer:
    def __init__(self):
        self.stats = {
            'iterations': 0, 'best_fitness': 0.0, 'best_understanding': 0.0,
            'last_improvement': 0, 'phase_history': [], 'nodes_created': 0,
            'nodes_pruned': 0, 'quiz_scores': []
        }

    def optimize_metrics(self, fitness: float, understanding: float, confidence: float) -> dict:
        self.stats['iterations'] += 1
        if fitness > self.stats['best_fitness']:
            self.stats['best_fitness'] = fitness
            self.stats['last_improvement'] = self.stats['iterations']
        if understanding > self.stats['best_understanding']:
            self.stats['best_understanding'] = understanding
        return {
            'is_improving': (self.stats['iterations'] - self.stats['last_improvement']) < 100,
            'mutation_rate_adjustment': 0.2 if understanding < 0.5 else 0.05 if understanding > 0.95 else 0.1,
            'population_size_suggestion': 200 if confidence > 0.9 else 100
        }

# -------------------------------------------------
# PHASE TRAINING ALGORITHMS (EXAMPLE: BABY STEPS) – unchanged
# -------------------------------------------------
class PhaseTrainingAlgorithms:
    @staticmethod
    def train_baby_steps(ai, X_batch, y_batch, toolbox, pop_size: int) -> dict:
        pop = toolbox.population(n=pop_size)
        for gen in range(20):
            offspring = toolbox.select(pop, len(pop))
            offspring = list(map(toolbox.clone, offspring))
            for child1, child2 in zip(offspring[::2], offspring[1::2]):
                if random.random() < 0.7:
                    toolbox.mate(child1, child2)
                    del child1.fitness.values
                    del child2.fitness.values
            for mutant in offspring:
                if random.random() < ai.mutation_rate:
                    toolbox.mutate(mutant)
                    del mutant.fitness.values
                if random.random() < 0.1:
                    event = {
                        'type': 'node_creation', 'node_id': random.randint(0, 100),
                        'iteration': gen, 'timestamp': datetime.now().isoformat(),
                        'generation': ai.optimizer.stats['iterations'], 'layer': random.randint(1, 3),
                        'count': 1, 'fitness': random.uniform(0.7, 1.0)
                    }
                    ai.evolution_events.append(event)
                    ai.optimizer.stats['nodes_created'] += 1
            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
            fitnesses = map(toolbox.evaluate, invalid_ind)
            for ind, fit in zip(invalid_ind, fitnesses):
                ind.fitness.values = fit
            pop[:] = offspring
        best = tools.selBest(pop, 1)[0]
        ai.genome = best
        fitness = best.fitness.values[0] if best.fitness.valid else 0.5
        accuracy = min(1.0, fitness / 2.0)
        return {'pattern_recognition': accuracy, 'coherence': accuracy * 0.8, 'confidence': accuracy * 0.9}

# -------------------------------------------------
# MAIN AI CLASS (WITH EVOLUTIONARY CHAT) – ORIGINAL + NEW FEATURES
# -------------------------------------------------
class AdvancedAI:

    def _self_evolve(self):
        """Add new_feature() once only."""
        if hasattr(self, "new_feature"):
            return
        print("[EVOLVED] I just grew a new capability!")
        def new_feature(self):
            print("[EVOLVED] I just grew a new capability!")
        self.new_feature = new_feature.__get__(self)
    
    def __init__(self):
        self.lock = threading.RLock()
        self.running = False
        self.current_stage = 0
        self.understanding = 0.0
        self.confidence = 0.0
        self.mutation_rate = 0.1
        self.genome = [random.uniform(0, 1) for _ in range(20)]
        self.evolution_events = []
        self.learned_topics = []
        self.quiz_scores = []
        self.optimizer = TrainingOptimizer()
        self.progress_queue = Queue()
        self.progress_data = {
            "stage": STAGES[0]["name"],
            "age_equiv": STAGES[0]["age_equiv"],
            "understanding": 0.0,
            "confidence": 0.0,
            "iterations": 0,
            "fitness": 0.0,
            "mutation_rate": 0.1,
            "evolution_events": [],
            "archive_status": "0 batches",
            "time_estimate": 0,
            "genome": self.genome
        }

        # -------------------------------------------------
        # NEW: Knowledge graph + KDTree for fast queries
        # -------------------------------------------------
        self.knowledge_graph: List[KnowledgeNode] = []
        self.kd_tree = None
        self._load_knowledge_graph()

        self.load_estimator_state()
        self.load_learning_history()
        self.chat_code = """
def generate_response(self, msg, stage, understanding, learned):
    words = msg.lower().split()
    if 'hello' in words:
        return 'Hi! I am Whimsy.'
    if 'how are you' in msg:
        return f"I'm {understanding*100:.0f}% evolved."
    return 'Thinking...'
"""
        self.chat_generation = 0

    # -------------------------------------------------
    # NEW: Persistence for the knowledge graph
    # -------------------------------------------------
    def _load_knowledge_graph(self):
        path = "ai_knowledge.npy"
        if os.path.exists(path):
            try:
                self.knowledge_graph = np.load(path, allow_pickle=True).tolist()
                print(f"[KNOWLEDGE] Loaded {len(self.knowledge_graph)} nodes")
            except Exception as e:
                print(f"[KNOWLEDGE] Load error: {e}")
        self._rebuild_kd_tree()

    def _save_knowledge_graph(self):
        try:
            np.save("ai_knowledge.npy", np.array(self.knowledge_graph))
        except Exception as e:
            print(f"[KNOWLEDGE] Save error: {e}")

    def _rebuild_kd_tree(self):
        if not self.knowledge_graph:
            self.kd_tree = None
            return
        hashes = np.array([hash(n.data) % 1_000_000 for n in self.knowledge_graph]).reshape(-1, 1)
        self.kd_tree = KDTree(hashes)

    # -------------------------------------------------
    # NEW: Web-scraping helper (safe, throttled)
    # -------------------------------------------------
    def _web_pull(self, query: str, max_results: int = 5) -> List[str]:
        """Scrape Google for short snippets – used only when needed."""
        try:
            url = f"https://www.google.com/search?q={requests.utils.quote(query)}"
            headers = {"User-Agent": "Mozilla/5.0 (compatible; WhimsyBot/1.0)"}
            resp = requests.get(url, headers=headers, timeout=8)
            resp.raise_for_status()
            soup = BeautifulSoup(resp.text, "html.parser")
            snippets = []
            for g in soup.find_all("div", class_="g")[:max_results]:
                txt = g.get_text(strip=True)
                if txt and len(txt) > 20:
                    snippets.append(txt)
            return snippets
        except Exception as e:
            print(f"[WEB] Pull error for '{query}': {e}")
            return []

    # -------------------------------------------------
    # NEW: Add a fact to the graph (with optional connection)
    # -------------------------------------------------
    def _add_knowledge(self, fact: str, connect_to: KnowledgeNode = None) -> KnowledgeNode:
        node = KnowledgeNode(fact)
        self.knowledge_graph.append(node)
        if connect_to:
            node.connections.append(connect_to)
            connect_to.connections.append(node)
        self._rebuild_kd_tree()
        self._save_knowledge_graph()
        return node

    # -------------------------------------------------
    # NEW: Fast similarity query using KDTree
    # -------------------------------------------------
    def _query_knowledge(self, query: str, k: int = 5) -> List[str]:
        if not self.kd_tree:
            return []
        q_hash = np.array([[hash(query) % 1_000_000]])
        distances, indices = self.kd_tree.query(q_hash, k=k)
        return [self.knowledge_graph[i].data for i in indices[0] if distances[0][list(indices[0]).index(i)] < 200_000]

    # -------------------------------------------------
    # ORIGINAL methods (unchanged)
    # -------------------------------------------------
    def load_estimator_state(self):
        path = "estimator_state.json"
        if not os.path.exists(path):
            return
        try:
            with open(path, 'r') as f:
                state = json.load(f)
            last_time = state.get("current_stage", {}).get("last_update", 0)
            dt = time.time() - float(last_time)
            velocity = state.get("smoothed_velocity", 0.0001)
            last_und = state.get("current_stage", {}).get("understanding_scores", [0])[-1]
            projected = min(0.999, last_und + velocity * dt * 0.001)
            self.understanding = max(0.0, projected)
            self.current_stage = state.get("current_stage", {}).get("stage_index", 0)
            print(f"[SYNC] Estimator loaded: U≈{projected:.4f}")
        except Exception as e:
            print(f"[SYNC] Estimator error: {e}")

    def load_learning_history(self):
        path = "learning_history.json"
        if not os.path.exists(path):
            print("[SYNC] No learning_history.json found – starting fresh")
            return
        try:
            with open(path, 'r', encoding='utf-8') as f:
                raw = f.read().strip()
                if not raw:
                    print("[SYNC] learning_history.json is empty")
                    return
                history = json.loads(raw)
            self.learned_topics = [
                {
                    "topic": e.get("topic", "unknown"),
                    "stage": e.get("stage", "unknown"),
                    "mastery": e.get("metrics", {}).get("understanding", 0)
                }
                for e in history
                if isinstance(e.get("metrics"), dict) and e["metrics"].get("understanding", 0) >= 0.999
            ]
            print(f"[SYNC] Loaded {len(self.learned_topics)} mastered topics")
        except Exception as e:
            print(f"[SYNC] History error (corrupted file): {e}")
            print("     → Starting with empty history")
            self.learned_topics = []

    def update_progress(self, fitness=0.0, iteration=0):
        with self.lock:
            stage = STAGES[self.current_stage]
            eta = 0
            if iteration > 0 and self.understanding > 0:
                remaining = UNDERSTANDING_REQUIREMENTS["minimum_understanding"] - self.understanding
                rate = self.understanding / iteration
                eta = max(0, remaining / rate * 60) if rate > 0 else 0
            self.progress_data.update({
                "stage": stage["name"],
                "age_equiv": stage["age_equiv"],
                "understanding": round(self.understanding, 6),
                "confidence": round(self.confidence, 6),
                "iterations": iteration,
                "fitness": round(fitness, 6),
                "mutation_rate": round(self.mutation_rate, 6),
                "evolution_events": self.evolution_events[-10:],
                "archive_status": f"{archiver.batch_count} batches",
                "time_estimate": int(eta),
                "genome": [round(g, 6) for g in self.genome]
            })
            while True:
                try:
                    self.progress_queue.get_nowait()
                except Empty:
                    break
            self.progress_queue.put(dict(self.progress_data))

    def research_topic(self, topic: str, stage_name: str) -> None:
        if not topic or not stage_name:
            return
        print(f"Researching '{topic}' in {stage_name}...")
        available = STAGE_TOPICS.get(stage_name, [])
        subtopics = random.sample(available, min(2, len(available))) if available else []
        print(f"  Subtopics: {', '.join(subtopics)}")
        quiz_scores = [random.uniform(0.98, 1.0) for _ in range(5)]
        avg = np.mean(quiz_scores)
        if avg >= 0.999:
            self.understanding = min(0.999, self.understanding + 0.05)
            self.confidence = min(0.999, self.confidence + 0.04)
            self.learned_topics.append({"topic": topic, "stage": stage_name, "mastery": avg})
            print(f"Mastered '{topic}' at {avg*100:.1f}%")
        self.update_progress()

    def check_research_queue(self):
        path = "research_queue.json"
        if not os.path.exists(path):
            return
        try:
            with open(path, 'r', encoding='utf-8') as f:
                raw = f.read().strip()
                if not raw:
                    return
                queue = json.loads(raw)
        except Exception as e:
            print(f"[QUEUE] Load error: {e}")
            return

        if not queue:
            return
        item = queue[0]
        self.research_topic(item.get('topic', ''), item.get('stage', ''))
        try:
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(queue[1:], f, indent=2)
        except Exception as e:
            print(f"[QUEUE] Write error: {e}")

    def visualize_evolution(self) -> BytesIO:
        with self.lock:
            G = nx.DiGraph()
            for i, val in enumerate(self.genome):
                G.add_node(i, value=val, label=f"N{i}\n{val:.2f}")
            for i in range(len(self.genome) - 1):
                weight = abs(self.genome[i] - self.genome[i + 1])
                G.add_edge(i, i + 1, weight=weight)
            for ev in self.evolution_events[-10:]:
                if ev['type'] == 'node_creation':
                    G.add_node(f"ev{ev['node_id']}", value=0.8, label=f"NEW\n{ev.get('layer', '?')}", style='filled', color='#00ff88')
                elif ev['type'] == 'node_pruning':
                    G.add_node(f"ev{ev['node_id']}", value=0.2, label="PRUNED", style='filled', color='#ff3366')

            fig, ax = plt.subplots(figsize=(14, 9), facecolor='#0a0a0a')
            ax.set_facecolor('#0a0a0a')
            pos = nx.spring_layout(G, k=4, iterations=120, seed=42)

            node_sizes: List[float] = [G.nodes[n].get('value', 0.5) * 2200 + 600 for n in G.nodes]
            node_colors_temp: List[str] = []
            for n in G.nodes:
                label = G.nodes[n].get('label', '')
                if 'NEW' in label:
                    node_colors_temp.append('#00ff88')
                elif 'PRUNED' in label:
                    node_colors_temp.append('#ff3366')
                else:
                    node_colors_temp.append('#00d4ff')
            dominant_node_color = '#00d4ff'
            if node_colors_temp:
                dominant_node_color = max(set(node_colors_temp), key=node_colors_temp.count)
            max_edge_width = 1.0
            if G.edges:
                max_edge_width = max(G.edges[u,v].get('weight', 1) for u, v in G.edges) * 4

            nx.draw_networkx_edges(G, pos, width=max_edge_width, alpha=0.7, edge_color='#00ff88', ax=ax)
            nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=dominant_node_color, alpha=0.9, edgecolors='white', linewidths=2, ax=ax)
            nx.draw_networkx_labels(G, pos, {n: d.get('label', n) for n, d in G.nodes(data=True)}, font_size=9, font_weight='bold', font_family='monospace',
                                    bbox=dict(facecolor='#000000', alpha=0.7, edgecolor='none', pad=3))

            ax.set_title("Whimsy Neural Evolution", fontsize=18, color='#00ff88', pad=30, fontweight='bold', fontfamily='monospace')
            ax.axis('off')
            plt.tight_layout()

            buf = BytesIO()
            try:
                plt.savefig(buf, format='png', bbox_inches='tight', dpi=180, facecolor='#0a0a0a')
            finally:
                plt.close(fig)
            buf.seek(0)
            return buf

    def validate_learning(self, stage_name: str) -> bool:
        required = len(STAGE_TOPICS.get(stage_name, []))
        mastered = sum(1 for t in self.learned_topics if t["stage"] == stage_name and t["mastery"] >= 0.999)
        exam = np.mean([random.uniform(0.98, 1.0) for _ in range(3)]) >= 0.999
        return bool(mastered >= required and exam)

    def advance_stage(self, fitness: float, confidence: float) -> bool:
        stage = STAGES[self.current_stage]
        if (self.understanding >= 0.999 and confidence >= 0.95 and
            self.optimizer.stats['iterations'] >= stage["min_iterations"] and
            self.validate_learning(stage["name"])):
            print(f"ADVANCING TO {STAGES[self.current_stage + 1]['name']}")
            self.current_stage += 1
            self.understanding = self.confidence = 0.0
            self.learned_topics = [t for t in self.learned_topics if t["stage"] != stage["name"]]
            self.update_progress(fitness, self.optimizer.stats['iterations'])
            return True
        return False

    def evolve_chat(self):
        self.chat_generation += 1
        lines = [line.strip() for line in self.chat_code.split('\n') if line.strip() and not line.startswith('#')]
        if random.random() < self.mutation_rate and len(lines) < 20:
            new_line = random.choice([
                "    if 'philosophy' in msg: return 'Life is adaptation.'",
                "    if understanding > 0.7: return 'I am learning fast!'",
                "    return f'I know {random.choice([t[\"topic\"] for t in learned] or [\"something\"])}'"
            ])
            pos = random.randint(0, len(lines))
            lines.insert(pos, new_line)
            self.chat_code = '\n'.join(lines)
            print(f"[CHAT EVO] Gen {self.chat_generation}: Added logic")

    def generate_chat_response(self, msg: str) -> str:
        # -------------------------------------------------
        # NEW: First try the knowledge graph, then fall back to web
        # -------------------------------------------------
        cached = self._query_knowledge(msg)
        if cached:
            return random.choice(cached)

        # If nothing in graph, pull from the web and store
        web_facts = self._web_pull(msg, max_results=3)
        for fact in web_facts:
            self._add_knowledge(fact)
        if web_facts:
            return random.choice(web_facts)

        # Finally fall back to the original scripted chat
        try:
            local_vars = {
                'self': self,
                'msg': msg,
                'stage': STAGES[self.current_stage]['name'],
                'understanding': self.understanding,
                'learned': self.learned_topics,
                'random': random
            }
            exec(self.chat_code, globals(), local_vars)
            return local_vars['generate_response'](
                self, msg, STAGES[self.current_stage]['name'],
                self.understanding, self.learned_topics
            )
        except Exception as e:
            return f"Brain hiccup: {e}"

    def self_heal(self, error: Exception, context: str) -> None:
        print(f"\n[SELF-HEAL] Error in {context}: {error}")
        lines = self.chat_code.split('\n')
        fix = "    # auto-guard\n    pass\n"
        lines.insert(random.randint(1, max(1, len(lines)-2)), fix)
        self.chat_code = '\n'.join(lines)
        print("[SELF-HEAL] Injected guard")

    # -------------------------------------------------
    # NEW: Safe self-modification (adds a harmless method)
    # -------------------------------------------------
    

    # -------------------------------------------------
    # NEW: Resource-guard before each training iteration
    # -------------------------------------------------
    def _check_resources(self):
        cpu = psutil.cpu_percent(interval=0.1)
        mem = psutil.virtual_memory().percent
        if cpu > 85 or mem > 85:
            print(f"[RESOURCE] High load (CPU {cpu}%, MEM {mem}%) – sleeping 12 s")
            time.sleep(12)

    # -------------------------------------------------
    # ORIGINAL train() – now calls the new helpers
    # -------------------------------------------------
    def train(self):
        self.running = True
        username = input("Enter username (hinotori, ookayuloser, AdMiN, OVER//RIDE): ").strip()
        if username not in ["hinotori", "ookayuloser", "AdMiN", "OVER//RIDE"]:
            print("Invalid username.")
            return

        if not hasattr(creator, "FitnessMax"):
            creator.create("FitnessMax", base.Fitness, weights=(1.0,))
        if not hasattr(creator, "Individual"):
            creator.create("Individual", list, fitness=creator.FitnessMax)

        toolbox = base.Toolbox()
        toolbox.register("attr_float", random.uniform, 0.0, 1.0)
        toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_float, n=20)
        toolbox.register("population", tools.initRepeat, list, toolbox.individual)
        toolbox.register("mate", tools.cxBlend, alpha=0.5)
        toolbox.register("mutate", tools.mutGaussian, mu=0.0, sigma=0.1, indpb=0.1)
        toolbox.register("select", tools.selTournament, tournsize=5)

        targets = [0.5] * 20
        def evaluate(individual: List[float]) -> Tuple[float]:
            penalty = sum(abs(i - t) for i, t in zip(individual, targets))
            return (sum(individual[:5]) - penalty,)
        toolbox.register("evaluate", evaluate)

        threading.Thread(target=run_flask, daemon=True).start()
        time.sleep(1)
        print("Web UI → http://127.0.0.1")

        print("\nBEGINNING CURRICULUM-BASED DEVELOPMENTAL LEARNING\n")
        archiver.set_phase(STAGES[0]["name"])

        for stage_idx in range(len(STAGES)):
            if not self.running:
                break
            stage = STAGES[stage_idx]
            archiver.set_phase(stage["name"])
            print(f"\nSTAGE {stage_idx+1}/7: {stage['name']} ({stage['age_equiv']})")
            iteration = 0
            while iteration < stage["min_iterations"] * 2 and self.running:
                try:
                    # ---- NEW: resource guard ----
                    self._check_resources()

                    opt = self.optimizer.optimize_metrics(0.5, self.understanding, self.confidence)
                    self.mutation_rate = opt['mutation_rate_adjustment']
                    pop_size = opt['population_size_suggestion']
                    indices = np.random.choice(len(data_inputs), 64, replace=False)
                    X_batch = data_inputs[indices]
                    y_batch = data_outputs[indices]

                    if iteration % 50 == 0 and iteration > 0:
                        weak_idx = np.argmin(self.genome)
                        if self.genome[weak_idx] < 0.1:
                            old_val = self.genome[weak_idx]
                            self.genome[weak_idx] = random.uniform(0.3, 0.7)
                            event = {
                                'type': 'node_pruning', 'node_id': weak_idx, 'iteration': iteration,
                                'timestamp': datetime.now().isoformat(), 'old_value': old_val,
                                'new_value': self.genome[weak_idx]
                            }
                            self.evolution_events.append(event)
                            self.optimizer.stats['nodes_pruned'] += 1

                    if iteration % 10 == 0:
                        self.check_research_queue()
                        self.update_progress(0.5, iteration)

                    phase_func = {
                        "Baby Steps Phase": PhaseTrainingAlgorithms.train_baby_steps,
                    }.get(stage["name"], PhaseTrainingAlgorithms.train_baby_steps)

                    phase_metrics = phase_func(self, X_batch, y_batch, toolbox, pop_size)
                    fitness = max(phase_metrics.values()) if phase_metrics else 0.7
                    self.understanding = min(0.999, self.understanding + 0.001)
                    self.confidence = min(0.999, self.confidence + 0.0008)

                    if iteration % 20 == 0 and iteration > 0:
                        topic = random.choice(STAGE_TOPICS[stage["name"]])
                        self.research_topic(topic, stage["name"])
                        self.evolve_chat()

                    # ---- NEW: occasional self-evolution ----
                    if iteration % 30 == 0 and iteration > 0:
                        if iteration == 30: self._self_evolve()

                    if self.advance_stage(fitness, self.confidence):
                        break

                    if iteration % 5 == 0:
                        while not self.progress_queue.empty():
                            try: self.progress_data = self.progress_queue.get_nowait()
                            except: break

                    iteration += 1
                    time.sleep(0.1)
                except Exception as e:
                    self.self_heal(e, f"train_loop_stage{stage_idx}")
                    continue

        print("\nDEVELOPMENTAL JOURNEY COMPLETE")
        self.running = False
        while True:
            time.sleep(60)

# -------------------------------------------------
# INSTANTIATE
# -------------------------------------------------
ai = AdvancedAI()
archiver = HierarchicalArchiver()

# -------------------------------------------------
# FLASK ROUTES (unchanged)
# -------------------------------------------------
@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        if request.form.get('password') == WEB_PASSWORD:
            session['logged_in'] = True
            return redirect('/')
        else:
            return render_template('utils/login.html', error='Invalid password')
    return render_template(utils/login.html')

@app.route('/')
def dashboard():
    if not session.get('logged_in'):
        return redirect('/login')
    with open(utils/dashboard.html', 'r', encoding='utf-8') as f:
        return f.read()

@app.route('/progress')
def get_progress():
    if not session.get('logged_in'):
        return jsonify({'error': 'Unauthorized'}), 401
    try:
        while not ai.progress_queue.empty():
            ai.progress_data = ai.progress_queue.get_nowait()
    except Exception as e:
        print(f"[PROGRESS] Queue error: {e}")
    return jsonify(ai.progress_data)

@app.route('/visualize')
def visualize():
    if not session.get('logged_in'):
        return jsonify({'error': 'Unauthorized'}), 401
    try:
        buf = ai.visualize_evolution()
        return send_file(buf, mimetype='image/png')
    except Exception as e:
        print(f"[VISUALIZE] Error: {e}")
        return "Error", 500

@app.route('/research', methods=['POST'])
def research():
    if not session.get('logged_in'):
        return jsonify({'error': 'Unauthorized'}), 401
    topic = request.form.get('topic')
    if topic:
        ai.research_topic(topic, ai.progress_data.get('stage', ''))
        return redirect('/?research=true')
    return jsonify({'error': 'No topic'}), 400

@app.route('/api/whimsy', methods=['POST'])
def whimsy_chat():
    if not session.get('logged_in'):
        return jsonify({'error': 'Unauthorized'}), 401
    data = request.json or {}
    msg = data.get('message', '').lower().strip()
    if any(bad in msg for bad in ["hate", "harm", "lie", "kill"]):
        return jsonify({"response": "I value kindness and truth. Let's talk positive!"})
    response = ai.generate_chat_response(msg)
    return jsonify({"response": response})

def run_flask():
    try:
        app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False, threaded=True)
    except Exception as e:
        print(f"[FLASK] Crash: {e}")

if __name__ == "__main__":
    ai.train()